{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the key events in the video:\n",
      "- 0:01: The woman is introduced as Saeko Shimada, a photographer in Tokyo.\n",
      "- 0:06: She mentions the city looks totally different at night compared to the day.\n",
      "- 0:13: She introduces a feature of the new Pixel called \"Video Boost\".\n",
      "- 0:17:  She talks about the \"Night Sight\" feature which boosts the quality of the videos captured at night.\n",
      "- 0:24: She talks about the place where she first moved to in Tokyo, a place called Sancha, and says she has many great memories there.\n",
      "- 0:30: The woman is impressed with the quality of the video captured using \"Night Sight\" feature. \n",
      "- 0:38: She describes an alley as beautiful.\n",
      "- 0:52: She arrives at Shibuya, a famous district of Tokyo. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "import os\n",
    "\n",
    "vertexai.init(project=os.environ.get('PROJECT_ID'), location=\"europe-west2\")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please identify the key events in this video. This should include all important and exciting events in the video.\n",
    "Please include the timestamps of these events in the output. \n",
    "\"\"\"\n",
    "# view at https://storage.googleapis.com/dcsgva-lab-cso-stephen-osulliv/formulae_2021_london_1.mp4\n",
    "video_file_uri = \"gs://dcsgva-lab-cso-stephen-osulliv/formulae_2021_london_1.mp4\"\n",
    "video_file = Part.from_uri(video_file_uri, mime_type=\"video/mp4\")\n",
    "\n",
    "contents = [video_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
